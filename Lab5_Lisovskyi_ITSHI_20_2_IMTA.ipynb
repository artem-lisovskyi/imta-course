{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Install the packages**"
      ],
      "metadata": {
        "id": "IMIJLlKoTki-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import the libraries**"
      ],
      "metadata": {
        "id": "1QPUSX-FTpAI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 583,
      "metadata": {
        "id": "aZUk2txrfv1u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download the data**"
      ],
      "metadata": {
        "id": "biR8U8sATf2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the stocks to test the model\n",
        "stocks = ['ORCL','EL','NOW','ADI','ISRG','CVS','T','EOG','REGN','TJX']\n",
        "stocks_compl = [\"AAPL\"] + stocks\n",
        "\n",
        "# Download the data for first stock and store it\n",
        "apl = yf.Ticker(\"AAPL\")\n",
        "aapl = apl.history(period ='5y')\n",
        "\n",
        "# Calculate the returns for the first stock and store it\n",
        "pct_aapl = aapl[\"Close\"].pct_change()\n",
        "\n",
        "prices_aapl = aapl[\"Close\"]\n",
        "returns = pct_aapl.to_frame()\n",
        "prices = prices_aapl.to_frame()\n",
        "\n",
        "# Store the generated returns and downloaded data\n",
        "returns = returns.rename(columns={\"Close\": stocks_compl[0]})\n",
        "prices = prices.rename(columns={\"Close\": stocks_compl[0]})\n",
        "\n",
        "# Downloading the stocks' data using the 'yfinance' library\n",
        "for stock in stocks:\n",
        "    df1 = yf.Ticker(stock)\n",
        "    df = df1.history(period='5y')\n",
        "\n",
        "    # Calculate the percent change\n",
        "    df_pct = df[\"Close\"].pct_change()\n",
        "    df_price = df[\"Close\"]\n",
        "\n",
        "    # Store the returns and prices\n",
        "    returns = returns.join(df_pct).rename(columns={\"Close\": stock})\n",
        "    prices = prices.join(df_price).rename(columns={\"Close\": stock})\n",
        "\n",
        "# Remove the empty cells from the returns dataframe\n",
        "returns = returns.dropna()"
      ],
      "metadata": {
        "id": "uWoDzC6vTbjC"
      },
      "execution_count": 584,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RECURSIVE BISECTION**"
      ],
      "metadata": {
        "id": "-d4kaujhVCRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rec_bipart(cov, sort_ix):\n",
        "\n",
        "    # compute HRP allocation\n",
        "\n",
        "    # intialize weights of 1\n",
        "    w = pd.Series(1, index=sort_ix)\n",
        "\n",
        "    # intialize all items in one cluster\n",
        "    c_items = [sort_ix]\n",
        "    while len(c_items) > 0:\n",
        "        c_items = [i[int(j):int(k)] for i in c_items for j,k in\n",
        "        ((0,len(i)/2),(len(i)/2,len(i))) if len(i)>1]\n",
        "        # now it has 2\n",
        "\n",
        "        for i in range(0, len(c_items), 2):\n",
        "            c_items0 = c_items[i] # cluster 1\n",
        "            c_items1 = c_items[i+1] # cluter 2\n",
        "            c_var0 = get_cluster_var(cov, c_items0)\n",
        "            c_var1 = get_cluster_var(cov, c_items1)\n",
        "            alpha = 1 - c_var0/(c_var0+c_var1)\n",
        "            w[c_items0] *= alpha\n",
        "            w[c_items1] *=1-alpha\n",
        "    return w"
      ],
      "metadata": {
        "id": "HZ39VenVu2NR"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **METHODS TO COMPARE THE STRATEGY**"
      ],
      "metadata": {
        "id": "3LBpom80VO_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the weights according to 'mean variance' method\n",
        "def compute_mean_varience_weights(covariances):\n",
        "    inv_covar = np.linalg.inv(covariances)\n",
        "    u = np.ones(len(covariances))\n",
        "    x = np.dot(inv_covar, u) / np.dot(u, np.dot(inv_covar, u))\n",
        "    return pd.Series(x, index = stocks_compl, name=\"Mean varience\")\n",
        "\n",
        "# Compute the weights according to 'risk parity' method\n",
        "def compute_risk_parity_weights(covariances):\n",
        "    weights = (1 / np.diag(covariances))\n",
        "    x = weights / sum(weights)\n",
        "    return pd.Series(x, index = stocks_compl, name=\"Risk parity\")\n",
        "\n",
        "# Compute the weights according to 'Monte Carlo' method\n",
        "def compute_monte_carlo_weights(covariances):\n",
        "    x = [1 / len(covariances) for i in range(len(covariances))]\n",
        "    return pd.Series(x, index = stocks_compl, name=\"Monte Carlo\")\n",
        "\n"
      ],
      "metadata": {
        "id": "30jBvtQeVYfB"
      },
      "execution_count": 586,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Store the weights generated from different methods**"
      ],
      "metadata": {
        "id": "t5LGKVZwXV3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the weights according to 'hrp' method\n",
        "cov = returns.cov()\n",
        "\n",
        "# Make a seperate dataframe to store the expected returns generated by all the methods used\n",
        "\n",
        "weights_mean_varience = compute_mean_varience_weights(cov)\n",
        "weights_risk_parity = compute_risk_parity_weights(cov)\n",
        "weights_monte_carlo = compute_monte_carlo_weights(cov)\n",
        "\n",
        "# Make a results dataframe containing results from all the methods\n",
        "results = weights_mean_varience.to_frame()\n",
        "results = results.join(weights_risk_parity.to_frame())\n",
        "results = results.join(weights_monte_carlo.to_frame())\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JinvzlwLkLNX",
        "outputId": "2420b881-2aaf-4f97-a424-e907d7047d35"
      },
      "execution_count": 587,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Mean varience  Risk parity  Monte Carlo\n",
            "AAPL       0.044085     0.094598     0.090909\n",
            "ORCL       0.124387     0.108556     0.090909\n",
            "EL         0.062053     0.076418     0.090909\n",
            "NOW       -0.012220     0.054063     0.090909\n",
            "ADI       -0.004111     0.081734     0.090909\n",
            "ISRG      -0.007181     0.077688     0.090909\n",
            "CVS        0.173233     0.124861     0.090909\n",
            "T          0.299197     0.143724     0.090909\n",
            "EOG        0.011555     0.042513     0.090909\n",
            "REGN       0.222419     0.097072     0.090909\n",
            "TJX        0.086583     0.098773     0.090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PARAMETERS TO COMPARE THE STRATEGIES**"
      ],
      "metadata": {
        "id": "JZBPW707XFr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Expected Returns**"
      ],
      "metadata": {
        "id": "HAFm2g6DWsBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function to compute the expected returns which takes the weight matrix as an argument\n",
        "\n",
        "def compute_ER(weights):\n",
        "    mean = returns.mean(0)\n",
        "    return weights.values * mean"
      ],
      "metadata": {
        "id": "Xx7NbfJDkQpb"
      },
      "execution_count": 588,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the weight matrix generated by different methods to the 'compute_ER' function\n",
        "# to get the expected returns\n",
        "\n",
        "er_mv = compute_ER(weights_mean_varience)\n",
        "er_mv.name = \"Mean variance\"\n",
        "er_rp = compute_ER(weights_risk_parity)\n",
        "er_rp.name = \"Risk parity\"\n",
        "er_unif = compute_ER(weights_monte_carlo)\n",
        "er_unif.name = \"Monte Carlo\""
      ],
      "metadata": {
        "id": "pvyw14pWkT2T"
      },
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a seperate dataframe to store the expected returns generated by all the methods used\n",
        "\n",
        "ers = er_mv.to_frame()\n",
        "ers = pd.concat([ers,er_rp.to_frame()])\n",
        "ers = pd.concat([ers,er_unif.to_frame()])\n",
        "ers = ers.sum()\n",
        "ers.name = \"Expected Return\"\n",
        "ers = ers.to_frame()\n",
        "print(ers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEVZfMFbmRze",
        "outputId": "488810f9-f2c2-4803-d1f0-28659d55b8cf"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Expected Return\n",
            "Mean variance         0.000555\n",
            "Risk parity           0.000732\n",
            "Monte Carlo           0.000789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Portfolio Volitality**"
      ],
      "metadata": {
        "id": "MMOUuInmWil8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function to calculate the volitality of the portfolio generated\n",
        "# by different methods which takes the weight matrix and covariance matrix as arguments\n",
        "\n",
        "def portfolio_volatility(weights, cov):\n",
        "    return np.sqrt(np.dot(np.dot(weights.values, cov.values), weights.values))"
      ],
      "metadata": {
        "id": "rv4Pq2-HmX4o"
      },
      "execution_count": 591,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the volitality of the various portfolio constructed by different methods\n",
        "\n",
        "data = [portfolio_volatility(weights_mean_varience, cov)]\n",
        "data.append(portfolio_volatility(weights_risk_parity, cov))\n",
        "data.append(portfolio_volatility(weights_monte_carlo, cov))\n",
        "volatility = pd.DataFrame(data = data, index=[\"Mean variance\", \"Risk parity\", \"Monte Carlo\"],\n",
        "columns=[\"Volatility\"])"
      ],
      "metadata": {
        "id": "W9mkqSi6mtau"
      },
      "execution_count": 592,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume the risk free return rate to be zero"
      ],
      "metadata": {
        "id": "yTlwhYWFWYgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def risk_free():\n",
        "    return 0"
      ],
      "metadata": {
        "id": "qYBPcz7AmwWB"
      },
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sharpe Ratio**"
      ],
      "metadata": {
        "id": "ziA5slldWK1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function to calculate the sharpe ratio of all the portfolios\n",
        "# which takes the weight matrix and covariance matrix as arguments\n",
        "\n",
        "def sharpe_ratio(weights, cov):\n",
        "    ret_portfolio = compute_ER(weights).sum()\n",
        "    ret_free = risk_free()\n",
        "    volatility = portfolio_volatility(weights, cov)\n",
        "    return (ret_portfolio - ret_free)/volatility"
      ],
      "metadata": {
        "id": "xvnkOYc3m5Ms"
      },
      "execution_count": 594,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the weight and covariance matrix to the 'sharpe_ratio' function\n",
        "\n",
        "data = [sharpe_ratio(weights_mean_varience, cov)]\n",
        "data.append(sharpe_ratio(weights_risk_parity, cov))\n",
        "data.append(sharpe_ratio(weights_monte_carlo, cov))\n",
        "sharpe_R= pd.DataFrame(data = data, index=[\"Mean variance\", \"Risk parity\", \"Monte Carlo\"],\n",
        "columns=[\"Sharpe Ratio\"])\n",
        "\n",
        "# Print the Sharpe ratio dataframe\n",
        "print(sharpe_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-kohZFim8h7",
        "outputId": "ece46e2a-fb75-42a8-da0a-4f64c27134a8"
      },
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Sharpe Ratio\n",
            "Mean variance      0.043960\n",
            "Risk parity        0.053527\n",
            "Monte Carlo        0.054835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Maximum Drawdown**"
      ],
      "metadata": {
        "id": "CctWDCirV_cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def max_drawdown(returns):\n",
        "    cumulative_returns = (1 + returns).cumprod()\n",
        "    peak = cumulative_returns.expanding(min_periods=1).max()\n",
        "    drawdown = (cumulative_returns - peak) / peak\n",
        "    max_drawdown = drawdown.min()\n",
        "    return max_drawdown\n",
        "\n",
        "data_drawdown = [max_drawdown(weights_mean_varience), max_drawdown(weights_risk_parity), max_drawdown(weights_monte_carlo)]\n",
        "dd = pd.DataFrame(data=data_drawdown, index=[\"Mean variance\", \"Risk parity\", \"Monte Carlo\"], columns=[\"Max DD\"])\n"
      ],
      "metadata": {
        "id": "xhJscAjRm9TY"
      },
      "execution_count": 596,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Profitability Ratio**"
      ],
      "metadata": {
        "id": "4iiUmyYAVoY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function to compute the Profitability Ratio for all the portfolios\n",
        "\n",
        "def profitability_ratio(weights, cov):\n",
        "    p_volatility = portfolio_volatility(weights, cov)\n",
        "    return np.dot(np.sqrt(np.diag(cov.values)), weights) / p_volatility"
      ],
      "metadata": {
        "id": "Nt5XDZlfoKhq"
      },
      "execution_count": 597,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the weights and covariance matrix to the 'diversification_ratio' function\n",
        "# and store the results in a seperate dataframe 'dr'\n",
        "\n",
        "data = [profitability_ratio(weights_mean_varience, cov)]\n",
        "data.append(profitability_ratio(weights_risk_parity, cov))\n",
        "data.append(profitability_ratio(weights_monte_carlo, cov))\n",
        "pr = pd.DataFrame(data = data, index=[\"Mean variance\", \"Risk parity\", \"Monte Carlo\"],\n",
        "columns = [\"Prof Ratio\"])"
      ],
      "metadata": {
        "id": "raULTfIUoRim"
      },
      "execution_count": 598,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FINAL RESULTS**"
      ],
      "metadata": {
        "id": "LjyQ4_RmVg8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join all the dataframes constructed in one dataframe to get final results\n",
        "\n",
        "final_results = ers.join(volatility)\n",
        "final_results = final_results.join(sharpe_R)\n",
        "final_results = final_results.join(dd)\n",
        "final_results = final_results.join(pr)\n",
        "print(final_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghPTotXKoXdj",
        "outputId": "a730ac8d-8810-4760-f6cd-2e8b56a92d9d"
      },
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Expected Return  Volatility  Sharpe Ratio    Max DD  Prof Ratio\n",
            "Mean variance         0.000555    0.012630      0.043960 -0.023344    1.485430\n",
            "Risk parity           0.000732    0.013682      0.053527  0.000000    1.508338\n",
            "Monte Carlo           0.000789    0.014382      0.054835  0.000000    1.513450\n"
          ]
        }
      ]
    }
  ]
}